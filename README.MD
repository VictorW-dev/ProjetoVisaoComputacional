# Sistema de DetecÃ§Ã£o de ViolÃªncia FÃ­sica em VÃ­deos de CÃ¢meras de SeguranÃ§a

Este projeto tem como objetivo desenvolver um sistema automatizado para detectar e classificar eventos de **violÃªncia fÃ­sica** em vÃ­deos de vigilÃ¢ncia, utilizando **estimativa de poses humanas com YOLO Pose** e **Redes Neurais Recorrentes (RNN, GRU, LSTM)**.

---

## ğŸ“‚ Estrutura do Projeto

```
projeto-violencia-fisica/
â”œâ”€â”€ data/                # Dados brutos, frames, keypoints e vetores
â”œâ”€â”€ models/              # Checkpoints de modelos treinados (.pth)
â”œâ”€â”€ report/              # RelatÃ³rio final e anÃ¡lises
â”œâ”€â”€ src/                 # Scripts principais do pipeline
â”œâ”€â”€ requirements.txt     # DependÃªncias do projeto
â””â”€â”€ README.md
```

---

## ğŸ§ª Etapas do Pipeline

1. **ExtraÃ§Ã£o de frames** dos vÃ­deos (`1_extract_frames.py`)
2. **Estimativa de poses humanas** com YOLOv8 Pose (`2_yolo_pose_inference.py`)
3. **ConstruÃ§Ã£o de vetores de caracterÃ­sticas** dos keypoints (`3_extract_features.py`)
   - Suporta mÃºltiplas pessoas por frame com o argumento `--max_people`
4. **ClassificaÃ§Ã£o temporal** com modelos RNN, GRU ou LSTM (`4_train_model.py`)
5. **AvaliaÃ§Ã£o do modelo** com mÃ©tricas e matriz de confusÃ£o (`5_evaluate_model.py`)
6. (Opcional) **Interface Web** com Streamlit (em desenvolvimento)
7. **ExecuÃ§Ã£o completa automatizada** com `run_pipeline.py`

---

## ğŸš€ Como rodar localmente

### 1. Crie um ambiente virtual e ative:

```bash
python -m venv venv
venv\Scripts\activate  # Windows
# ou
source venv/bin/activate  # Linux/Mac
```

### 2. Instale as dependÃªncias:

```bash
pip install -r requirements.txt
```

---

## ğŸ“¼ Exemplo de uso com `run_pipeline.py`

### PrÃ©-requisitos:
- Coloque os vÃ­deos em `data/raw/` com nomes como:
  - `Fight1.mp4`, `Normal1.mp4`, `Fight2.mp4`, `Normal2.mp4`

### Comando Ãºnico para processar tudo:

```bash
python src/run_pipeline.py ^
  --model lstm ^
  --fps 10 ^
  --max_people 5 ^
  --train_violence Fight1 ^
  --train_nonviolence Normal1 ^
  --test_violence Fight2 ^
  --test_nonviolence Normal2
```

---

## âš™ï¸ ParÃ¢metros Ãºteis

- `--model`: tipo de modelo (`lstm`, `gru` ou `rnn`)
- `--fps`: taxa de quadros para extraÃ§Ã£o de frames
- `--max_people`: nÃºmero mÃ¡ximo de pessoas consideradas por frame (default = 3)

---

## ğŸ“Œ Tema

**ViolÃªncia FÃ­sica**

Este projeto utiliza vÃ­deos do **Real-World Violence Dataset** e/ou outros contextos de vigilÃ¢ncia para detectar comportamentos agressivos de forma automatizada.

---

## ğŸ“Š MÃ©tricas de exemplo (teste real)

- **AcurÃ¡cia geral:** 92.8%
- **Recall (violÃªncia):** 100%
- **Falsos positivos:** 9
- **Falsos negativos:** 0

> O sistema Ã© altamente sensÃ­vel a eventos de violÃªncia, priorizando a nÃ£o perda de detecÃ§Ãµes relevantes.

---

## âš ï¸ ObservaÃ§Ãµes

- O vetor por frame Ã© composto pelos keypoints de atÃ© `N` pessoas (`N Ã— 34` valores).
- Se houver menos pessoas no frame, o vetor Ã© preenchido com zeros.
- Se houver mais, apenas as primeiras `N` pessoas detectadas sÃ£o consideradas.
- Isso permite entrada fixa para as redes neurais recorrentes.

---

## ğŸ‘¨â€ğŸ’» Desenvolvido por

[Victor Winicius Barros Santos](https://github.com/VictorW-dev)
